{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import skimage\n",
    "from skimage.transform import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = chainer.datasets.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8ANJEX4gKcIPJEX4gaQIP5DU/wOioX625EdELgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "7\n",
      "10000\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "for i in range(len(train)):\n",
    "    image = rotate((train[i][0]).reshape(28,28), np.random.randint(0,360))\n",
    "    train_images += [image]\n",
    "\n",
    "test_images = []\n",
    "for i in range(len(test)):\n",
    "    image = rotate((test[i][0]).reshape(28,28), np.random.randint(0,360))\n",
    "    test_images += [image]\n",
    "    \n",
    "train_labels = []\n",
    "for i in range(len(train)):\n",
    "    train_labels += [train[i][1]]\n",
    "\n",
    "test_labels = []\n",
    "for i in range(len(test)):\n",
    "    test_labels += [test[i][1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add one dimension so that it can be an input for the NN\n",
    "X_train = np.array(train_images).reshape(60000, 1, 28, 28)\n",
    "X_test = np.array(test_images).reshape(10000, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "y_train = torch.from_numpy(np.array(train_labels).reshape(60000))\n",
    "y_test = torch.from_numpy(np.array(test_labels).reshape(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join the x and y values\n",
    "import torch.utils.data as data_utils\n",
    "train = data_utils.TensorDataset(X_train, y_train)\n",
    "test = data_utils.TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train, batch_size=64, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \"\"\"Convnet Classifier\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(3, 3), padding=1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        )\n",
    "        # Logistic Regression\n",
    "        self.clf = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.clf(self.conv(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Classifier()\n",
    "if cuda_available:\n",
    "    clf = clf.cuda()\n",
    "optimizer = torch.optim.Adam(clf.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss : 0.293 \n",
      "Epoch : 0 Test Acc : 94.030\n",
      "Epoch : 0 Test Loss : 0.367\n",
      "UPDATE: NEW BEST MODEL\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 94.02999877929688 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 1 Loss : 0.289 \n",
      "Epoch : 1 Test Acc : 93.720\n",
      "Epoch : 1 Test Loss : 0.364\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.30999755859375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 2 Loss : 0.284 \n",
      "Epoch : 2 Test Acc : 94.030\n",
      "Epoch : 2 Test Loss : 0.359\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.30999755859375 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 3 Loss : 0.283 \n",
      "Epoch : 3 Test Acc : 93.900\n",
      "Epoch : 3 Test Loss : 0.356\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.12999725341796875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 4 Loss : 0.284 \n",
      "Epoch : 4 Test Acc : 93.860\n",
      "Epoch : 4 Test Loss : 0.359\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.04000091552734375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 5 Loss : 0.274 \n",
      "Epoch : 5 Test Acc : 94.050\n",
      "Epoch : 5 Test Loss : 0.347\n",
      "UPDATE: NEW BEST MODEL\n",
      "Iterator for early stopping now at 3 since improvement of test accuracy = 0.19000244140625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 6 Loss : 0.273 \n",
      "Epoch : 6 Test Acc : 93.300\n",
      "Epoch : 6 Test Loss : 0.347\n",
      "Iterator for early stopping now at 4 since improvement of test accuracy = -0.75 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 7 Loss : 0.277 \n",
      "Epoch : 7 Test Acc : 94.100\n",
      "Epoch : 7 Test Loss : 0.349\n",
      "UPDATE: NEW BEST MODEL\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.7999954223632812 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 8 Loss : 0.274 \n",
      "Epoch : 8 Test Acc : 93.620\n",
      "Epoch : 8 Test Loss : 0.349\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.4799957275390625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 9 Loss : 0.274 \n",
      "Epoch : 9 Test Acc : 93.960\n",
      "Epoch : 9 Test Loss : 0.346\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.339996337890625 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 10 Loss : 0.274 \n",
      "Epoch : 10 Test Acc : 94.270\n",
      "Epoch : 10 Test Loss : 0.348\n",
      "UPDATE: NEW BEST MODEL\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.30999755859375 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 11 Loss : 0.273 \n",
      "Epoch : 11 Test Acc : 92.970\n",
      "Epoch : 11 Test Loss : 0.351\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -1.2999954223632812 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 12 Loss : 0.270 \n",
      "Epoch : 12 Test Acc : 93.850\n",
      "Epoch : 12 Test Loss : 0.345\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.8799972534179688 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 13 Loss : 0.263 \n",
      "Epoch : 13 Test Acc : 93.460\n",
      "Epoch : 13 Test Loss : 0.339\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.3899993896484375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 14 Loss : 0.266 \n",
      "Epoch : 14 Test Acc : 93.510\n",
      "Epoch : 14 Test Loss : 0.341\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = 0.0500030517578125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 15 Loss : 0.264 \n",
      "Epoch : 15 Test Acc : 94.460\n",
      "Epoch : 15 Test Loss : 0.333\n",
      "UPDATE: NEW BEST MODEL\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.9499969482421875 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 16 Loss : 0.260 \n",
      "Epoch : 16 Test Acc : 93.710\n",
      "Epoch : 16 Test Loss : 0.336\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.75 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 17 Loss : 0.260 \n",
      "Epoch : 17 Test Acc : 94.220\n",
      "Epoch : 17 Test Loss : 0.332\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.5100021362304688 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 18 Loss : 0.258 \n",
      "Epoch : 18 Test Acc : 93.550\n",
      "Epoch : 18 Test Loss : 0.332\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.6699981689453125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 19 Loss : 0.256 \n",
      "Epoch : 19 Test Acc : 93.430\n",
      "Epoch : 19 Test Loss : 0.331\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.12000274658203125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 20 Loss : 0.255 \n",
      "Epoch : 20 Test Acc : 94.450\n",
      "Epoch : 20 Test Loss : 0.327\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 1.0199966430664062 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 21 Loss : 0.254 \n",
      "Epoch : 21 Test Acc : 93.790\n",
      "Epoch : 21 Test Loss : 0.329\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.6599960327148438 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 22 Loss : 0.253 \n",
      "Epoch : 22 Test Acc : 94.040\n",
      "Epoch : 22 Test Loss : 0.325\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.25 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 23 Loss : 0.249 \n",
      "Epoch : 23 Test Acc : 94.310\n",
      "Epoch : 23 Test Loss : 0.319\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.26999664306640625 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 24 Loss : 0.248 \n",
      "Epoch : 24 Test Acc : 93.990\n",
      "Epoch : 24 Test Loss : 0.322\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.31999969482421875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 25 Loss : 0.252 \n",
      "Epoch : 25 Test Acc : 93.640\n",
      "Epoch : 25 Test Loss : 0.326\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.34999847412109375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 26 Loss : 0.249 \n",
      "Epoch : 26 Test Acc : 93.770\n",
      "Epoch : 26 Test Loss : 0.323\n",
      "Iterator for early stopping now at 3 since improvement of test accuracy = 0.12999725341796875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 27 Loss : 0.249 \n",
      "Epoch : 27 Test Acc : 93.440\n",
      "Epoch : 27 Test Loss : 0.324\n",
      "Iterator for early stopping now at 4 since improvement of test accuracy = -0.32999420166015625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 28 Loss : 0.248 \n",
      "Epoch : 28 Test Acc : 94.290\n",
      "Epoch : 28 Test Loss : 0.319\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.8499984741210938 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 29 Loss : 0.239 \n",
      "Epoch : 29 Test Acc : 93.790\n",
      "Epoch : 29 Test Loss : 0.313\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.5 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 30 Loss : 0.241 \n",
      "Epoch : 30 Test Acc : 94.100\n",
      "Epoch : 30 Test Loss : 0.311\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.30999755859375 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 31 Loss : 0.246 \n",
      "Epoch : 31 Test Acc : 94.340\n",
      "Epoch : 31 Test Loss : 0.317\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.23999786376953125 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 32 Loss : 0.243 \n",
      "Epoch : 32 Test Acc : 94.830\n",
      "Epoch : 32 Test Loss : 0.309\n",
      "UPDATE: NEW BEST MODEL\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.4900054931640625 > 0.2\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 33 Loss : 0.244 \n",
      "Epoch : 33 Test Acc : 94.160\n",
      "Epoch : 33 Test Loss : 0.315\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.6699981689453125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 34 Loss : 0.242 \n",
      "Epoch : 34 Test Acc : 94.410\n",
      "Epoch : 34 Test Loss : 0.313\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.25 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 35 Loss : 0.237 \n",
      "Epoch : 35 Test Acc : 94.380\n",
      "Epoch : 35 Test Loss : 0.309\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.03000640869140625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 36 Loss : 0.239 \n",
      "Epoch : 36 Test Acc : 93.940\n",
      "Epoch : 36 Test Loss : 0.312\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.43999481201171875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 37 Loss : 0.235 \n",
      "Epoch : 37 Test Acc : 94.520\n",
      "Epoch : 37 Test Loss : 0.304\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.5799942016601562 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 38 Loss : 0.240 \n",
      "Epoch : 38 Test Acc : 93.960\n",
      "Epoch : 38 Test Loss : 0.311\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.55999755859375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 39 Loss : 0.234 \n",
      "Epoch : 39 Test Acc : 94.140\n",
      "Epoch : 39 Test Loss : 0.303\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = 0.18000030517578125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 40 Loss : 0.231 \n",
      "Epoch : 40 Test Acc : 93.740\n",
      "Epoch : 40 Test Loss : 0.302\n",
      "Iterator for early stopping now at 3 since improvement of test accuracy = -0.40000152587890625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 41 Loss : 0.237 \n",
      "Epoch : 41 Test Acc : 93.490\n",
      "Epoch : 41 Test Loss : 0.310\n",
      "Iterator for early stopping now at 4 since improvement of test accuracy = -0.25 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 42 Loss : 0.233 \n",
      "Epoch : 42 Test Acc : 94.730\n",
      "Epoch : 42 Test Loss : 0.300\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 1.2400054931640625 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 43 Loss : 0.232 \n",
      "Epoch : 43 Test Acc : 93.750\n",
      "Epoch : 43 Test Loss : 0.302\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.9800033569335938 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 44 Loss : 0.234 \n",
      "Epoch : 44 Test Acc : 94.120\n",
      "Epoch : 44 Test Loss : 0.302\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.37000274658203125 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 45 Loss : 0.236 \n",
      "Epoch : 45 Test Acc : 94.050\n",
      "Epoch : 45 Test Loss : 0.309\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.06999969482421875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 46 Loss : 0.229 \n",
      "Epoch : 46 Test Acc : 93.950\n",
      "Epoch : 46 Test Loss : 0.298\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.100006103515625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 47 Loss : 0.233 \n",
      "Epoch : 47 Test Acc : 93.870\n",
      "Epoch : 47 Test Loss : 0.305\n",
      "Iterator for early stopping now at 3 since improvement of test accuracy = -0.07999420166015625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 48 Loss : 0.228 \n",
      "Epoch : 48 Test Acc : 94.440\n",
      "Epoch : 48 Test Loss : 0.297\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.5699996948242188 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 49 Loss : 0.228 \n",
      "Epoch : 49 Test Acc : 93.800\n",
      "Epoch : 49 Test Loss : 0.299\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.6399993896484375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 50 Loss : 0.227 \n",
      "Epoch : 50 Test Acc : 93.470\n",
      "Epoch : 50 Test Loss : 0.301\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.3300018310546875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 51 Loss : 0.227 \n",
      "Epoch : 51 Test Acc : 93.910\n",
      "Epoch : 51 Test Loss : 0.300\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.44000244140625 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 52 Loss : 0.227 \n",
      "Epoch : 52 Test Acc : 94.400\n",
      "Epoch : 52 Test Loss : 0.295\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.48999786376953125 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 53 Loss : 0.227 \n",
      "Epoch : 53 Test Acc : 93.750\n",
      "Epoch : 53 Test Loss : 0.301\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.6500015258789062 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 54 Loss : 0.228 \n",
      "Epoch : 54 Test Acc : 94.310\n",
      "Epoch : 54 Test Loss : 0.297\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.55999755859375 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 55 Loss : 0.223 \n",
      "Epoch : 55 Test Acc : 94.070\n",
      "Epoch : 55 Test Loss : 0.291\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.23999786376953125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 56 Loss : 0.224 \n",
      "Epoch : 56 Test Acc : 94.190\n",
      "Epoch : 56 Test Loss : 0.291\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = 0.12000274658203125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 57 Loss : 0.221 \n",
      "Epoch : 57 Test Acc : 93.740\n",
      "Epoch : 57 Test Loss : 0.294\n",
      "Iterator for early stopping now at 3 since improvement of test accuracy = -0.45000457763671875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 58 Loss : 0.225 \n",
      "Epoch : 58 Test Acc : 93.990\n",
      "Epoch : 58 Test Loss : 0.295\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.25 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 59 Loss : 0.220 \n",
      "Epoch : 59 Test Acc : 93.340\n",
      "Epoch : 59 Test Loss : 0.292\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.6500015258789062 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 60 Loss : 0.218 \n",
      "Epoch : 60 Test Acc : 94.000\n",
      "Epoch : 60 Test Loss : 0.289\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.660003662109375 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 61 Loss : 0.217 \n",
      "Epoch : 61 Test Acc : 94.430\n",
      "Epoch : 61 Test Loss : 0.287\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.43000030517578125 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 62 Loss : 0.222 \n",
      "Epoch : 62 Test Acc : 94.140\n",
      "Epoch : 62 Test Loss : 0.292\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.29000091552734375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 63 Loss : 0.216 \n",
      "Epoch : 63 Test Acc : 93.840\n",
      "Epoch : 63 Test Loss : 0.288\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.3000030517578125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 64 Loss : 0.220 \n",
      "Epoch : 64 Test Acc : 93.410\n",
      "Epoch : 64 Test Loss : 0.293\n",
      "Iterator for early stopping now at 3 since improvement of test accuracy = -0.42999267578125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 65 Loss : 0.221 \n",
      "Epoch : 65 Test Acc : 93.710\n",
      "Epoch : 65 Test Loss : 0.291\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.29999542236328125 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 66 Loss : 0.218 \n",
      "Epoch : 66 Test Acc : 93.890\n",
      "Epoch : 66 Test Loss : 0.287\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = 0.18000030517578125 <= 0.2\n",
      "--------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 67 Loss : 0.215 \n",
      "Epoch : 67 Test Acc : 93.200\n",
      "Epoch : 67 Test Loss : 0.288\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.69000244140625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 68 Loss : 0.216 \n",
      "Epoch : 68 Test Acc : 93.720\n",
      "Epoch : 68 Test Loss : 0.287\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.5200042724609375 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 69 Loss : 0.214 \n",
      "Epoch : 69 Test Acc : 93.710\n",
      "Epoch : 69 Test Loss : 0.286\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.01000213623046875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 70 Loss : 0.215 \n",
      "Epoch : 70 Test Acc : 93.160\n",
      "Epoch : 70 Test Loss : 0.288\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.5499954223632812 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 71 Loss : 0.215 \n",
      "Epoch : 71 Test Acc : 93.970\n",
      "Epoch : 71 Test Loss : 0.285\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.80999755859375 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 72 Loss : 0.215 \n",
      "Epoch : 72 Test Acc : 93.310\n",
      "Epoch : 72 Test Loss : 0.288\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.660003662109375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 73 Loss : 0.210 \n",
      "Epoch : 73 Test Acc : 94.020\n",
      "Epoch : 73 Test Loss : 0.279\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.7099990844726562 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 74 Loss : 0.214 \n",
      "Epoch : 74 Test Acc : 94.230\n",
      "Epoch : 74 Test Loss : 0.283\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.2100067138671875 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 75 Loss : 0.213 \n",
      "Epoch : 75 Test Acc : 93.370\n",
      "Epoch : 75 Test Loss : 0.284\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.8600006103515625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 76 Loss : 0.210 \n",
      "Epoch : 76 Test Acc : 92.810\n",
      "Epoch : 76 Test Loss : 0.285\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.5600051879882812 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 77 Loss : 0.215 \n",
      "Epoch : 77 Test Acc : 93.890\n",
      "Epoch : 77 Test Loss : 0.283\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 1.0800018310546875 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 78 Loss : 0.211 \n",
      "Epoch : 78 Test Acc : 93.080\n",
      "Epoch : 78 Test Loss : 0.283\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.80999755859375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 79 Loss : 0.212 \n",
      "Epoch : 79 Test Acc : 94.140\n",
      "Epoch : 79 Test Loss : 0.283\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 1.05999755859375 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 80 Loss : 0.213 \n",
      "Epoch : 80 Test Acc : 93.950\n",
      "Epoch : 80 Test Loss : 0.281\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.19000244140625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 81 Loss : 0.210 \n",
      "Epoch : 81 Test Acc : 93.200\n",
      "Epoch : 81 Test Loss : 0.281\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.75 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 82 Loss : 0.212 \n",
      "Epoch : 82 Test Acc : 93.320\n",
      "Epoch : 82 Test Loss : 0.283\n",
      "Iterator for early stopping now at 3 since improvement of test accuracy = 0.12000274658203125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 83 Loss : 0.210 \n",
      "Epoch : 83 Test Acc : 93.970\n",
      "Epoch : 83 Test Loss : 0.280\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.6500015258789062 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 84 Loss : 0.208 \n",
      "Epoch : 84 Test Acc : 93.790\n",
      "Epoch : 84 Test Loss : 0.277\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.18000030517578125 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 85 Loss : 0.209 \n",
      "Epoch : 85 Test Acc : 93.710\n",
      "Epoch : 85 Test Loss : 0.280\n",
      "Iterator for early stopping now at 2 since improvement of test accuracy = -0.0800018310546875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 86 Loss : 0.210 \n",
      "Epoch : 86 Test Acc : 93.390\n",
      "Epoch : 86 Test Loss : 0.281\n",
      "Iterator for early stopping now at 3 since improvement of test accuracy = -0.31999969482421875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 87 Loss : 0.205 \n",
      "Epoch : 87 Test Acc : 93.420\n",
      "Epoch : 87 Test Loss : 0.275\n",
      "Iterator for early stopping now at 4 since improvement of test accuracy = 0.029998779296875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 88 Loss : 0.204 \n",
      "Epoch : 88 Test Acc : 93.630\n",
      "Epoch : 88 Test Loss : 0.272\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.20999908447265625 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 89 Loss : 0.205 \n",
      "Epoch : 89 Test Acc : 93.780\n",
      "Epoch : 89 Test Loss : 0.273\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = 0.15000152587890625 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 90 Loss : 0.210 \n",
      "Epoch : 90 Test Acc : 94.320\n",
      "Epoch : 90 Test Loss : 0.276\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.5400009155273438 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 91 Loss : 0.208 \n",
      "Epoch : 91 Test Acc : 92.910\n",
      "Epoch : 91 Test Loss : 0.282\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -1.4099960327148438 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 92 Loss : 0.203 \n",
      "Epoch : 92 Test Acc : 93.430\n",
      "Epoch : 92 Test Loss : 0.272\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.5199966430664062 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 93 Loss : 0.206 \n",
      "Epoch : 93 Test Acc : 92.470\n",
      "Epoch : 93 Test Loss : 0.278\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.9599990844726562 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 94 Loss : 0.209 \n",
      "Epoch : 94 Test Acc : 94.310\n",
      "Epoch : 94 Test Loss : 0.275\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 1.839996337890625 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 95 Loss : 0.200 \n",
      "Epoch : 95 Test Acc : 93.360\n",
      "Epoch : 95 Test Loss : 0.270\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -0.9499969482421875 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 96 Loss : 0.204 \n",
      "Epoch : 96 Test Acc : 94.130\n",
      "Epoch : 96 Test Loss : 0.270\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.7699966430664062 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 97 Loss : 0.206 \n",
      "Epoch : 97 Test Acc : 92.560\n",
      "Epoch : 97 Test Loss : 0.279\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = -1.5699996948242188 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 98 Loss : 0.201 \n",
      "Epoch : 98 Test Acc : 93.520\n",
      "Epoch : 98 Test Loss : 0.269\n",
      "Iterator for early stopping reset to 0 since improvement of test accuracy = 0.9599990844726562 > 0.2\n",
      "--------------------------------------------------------------\n",
      "Epoch : 99 Loss : 0.198 \n",
      "Epoch : 99 Test Acc : 93.690\n",
      "Epoch : 99 Test Loss : 0.267\n",
      "Iterator for early stopping now at 1 since improvement of test accuracy = 0.17000579833984375 <= 0.2\n",
      "--------------------------------------------------------------\n",
      "Training time for 99 epochs: 0:30:04.202179\n"
     ]
    }
   ],
   "source": [
    "time1=dt.datetime.now()\n",
    "\n",
    "#Will print the plots\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "valid_acc = []\n",
    "\n",
    "patience = 6\n",
    "epsilon = 0.2\n",
    "patience_iterator = 0\n",
    "best_test_acc = 0\n",
    "last_acc = 0\n",
    "stop = False\n",
    "\n",
    "for epoch in range(50):\n",
    "    losses = []\n",
    "    # Train\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        if cuda_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = clf(inputs.float())\n",
    "        loss = criterion(outputs, targets.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data)\n",
    "    avg_train_losses.append(np.mean(losses))\n",
    "    print('Epoch : %d Loss : %.3f ' % (epoch, np.mean(losses)))\n",
    "    \n",
    "    # Evaluate\n",
    "    clf.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        if cuda_available:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = clf(inputs.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum()\n",
    "        loss = criterion(outputs, targets.long())\n",
    "        losses.append(loss.data)\n",
    "    \n",
    "    avg_valid_losses.append(np.mean(losses))\n",
    "    test_acc = 100.*correct/total\n",
    "    valid_acc.append(test_acc)\n",
    "        \n",
    "    print('Epoch : %d Test Acc : %.3f' % (epoch, test_acc))\n",
    "    print('Epoch : %d Test Loss : %.3f' % (epoch, np.mean(losses)))\n",
    "   \n",
    "    if test_acc > best_test_acc and not(stop):\n",
    "        print('UPDATE: NEW BEST MODEL')\n",
    "        torch.save(clf.state_dict(), 'best_model_mnist.mdl')\n",
    "        best_test_acc = test_acc\n",
    "    if test_acc <= last_acc + epsilon:\n",
    "        patience_iterator = patience_iterator + 1\n",
    "        print('Iterator for early stopping now at '+str(patience_iterator)+' since improvement of test accuracy = '+str((test_acc-last_acc).item())+' <= '+str(epsilon))\n",
    "    else:\n",
    "        patience_iterator = 0\n",
    "        print('Iterator for early stopping reset to 0 since improvement of test accuracy = '+str((test_acc-last_acc).item())+' > '+str(epsilon))\n",
    "    \n",
    "    if patience_iterator == patience:\n",
    "        stop = True\n",
    "        print('Early Stopping')\n",
    "    print('--------------------------------------------------------------')\n",
    "    last_acc = test_acc\n",
    "    clf.train()\n",
    "    \n",
    "time2 = dt.datetime.now()\n",
    "print('Training time for '+str(epoch)+' epochs: '+str(time2-time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minposs = 0\n",
    "for i in range(len(valid_acc)):\n",
    "    if best_test_acc == valid_acc[i]:\n",
    "        minposs = i\n",
    "minposs += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): Dropout(p=0.5, inplace=False)\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): Dropout(p=0.5, inplace=False)\n",
       "    (14): ReLU()\n",
       "    (15): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (clf): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Later to restore the best model\n",
    "clf.load_state_dict(torch.load('best_model_mnist.mdl'))\n",
    "clf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import test images\n",
    "test_images = pd.read_pickle('test_max_x')\n",
    "test_images = (test_images >= 250).astype(float)*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "# Extract digits\n",
    "import skimage\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.transform import resize\n",
    "\n",
    "def top_regions(labeled):\n",
    "    one = 0\n",
    "    two = 0\n",
    "    three = 0\n",
    "    regions = regionprops(labeled)\n",
    "    \n",
    "\n",
    "    for region in regions:\n",
    "        if region.area > three:\n",
    "            three = region.area\n",
    "        if region.area > two:\n",
    "            three = two\n",
    "            two = region.area\n",
    "        if region.area > one:\n",
    "            three = two\n",
    "            two = one\n",
    "            one = region.area\n",
    "        \n",
    "    top_region = []\n",
    "    for region in regions:\n",
    "        if region.area == one:\n",
    "            top_region += [region]\n",
    "            one = 0\n",
    "            \n",
    "        if region.area == two:\n",
    "            top_region += [region]\n",
    "            two = 0\n",
    "            \n",
    "        if region.area == three:\n",
    "            top_region += [region]\n",
    "            three = 0\n",
    "        \n",
    "    return top_region\n",
    "            \n",
    "\n",
    "def get_digits(images, num):\n",
    "    labeled = label(images[num], neighbors = 8, connectivity = 2)                \n",
    "    digits = []\n",
    "    \n",
    "    # find top three area regions \n",
    "    top_3 = top_regions(labeled)\n",
    "    \n",
    "    for region in top_3: \n",
    "        (min_row, min_col, max_row, max_col) = region.bbox\n",
    "        digit = images[num][max(min_row - 10, 0) :min(max_row + 10, 128), max(min_col- 10,0): min(max_col+10, 128)]\n",
    "        digits += [digit]\n",
    "        \n",
    "    return digits\n",
    "\n",
    "\n",
    "# Resize the digits\n",
    "def resize_digits(dgts, size):\n",
    "    new_dgts = []\n",
    "    for digit in dgts:\n",
    "        digit_resized = resize(digit, (size,size), anti_aliasing = True)\n",
    "        new_dgts += [digit_resized]\n",
    "    return new_dgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABI1JREFUeJzt3duO0zAUQNEY8f+/bB4QEsx02nSa\nkste6xFxaRDZPnZTOuacC9D1Y+8XAOxLBCBOBCBOBCBOBCBOBCBOBCBOBCDu594vYFmWZYzhiSV4\nsznnuPXjJgGIEwGIEwGIEwGIEwGIEwGIEwGIEwGIEwGIEwGIEwGIEwGIEwGIEwGIO8RHidnere+T\nGOPmJ0mJMwlAnEngYnyjFM8yCUCcCECcCFyIrQDfIQIQ52DwAkwAvMIkAHEmgYvzgBCPmAQgTgQg\nTgQgTgQgTgQgTgQgTgQgznMCJ+ZJQbZgEoA4k8BJPZoCPCnIWiYBiDMJnIxzALYmAiex9ua3DeBZ\ntgMQJwIXYgrgO0QA4kTgBBwG8k4iAHHeHbgAZwG8wiRwAl/d5GMMAeBlIgBxtgMnYcXnXUwCECcC\nECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcC\nECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcC\nECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcC\nECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcCECcC\nECcCECcCECcCECcCEPdz7xdwFXPO1T93jPHGVwLPMQlAnElgA89MAV/9fNMBezEJQJwIvGDO+fQU\ncO/3gj2IAMQ5E3jBn338s3t8qz5HIgIbePZQb4whBByG7QDEicAOTAEciQhAnAgchIeF2IuDweXz\neP6uG9I2gCMyCUBcbhJYsxpv9Wy/lZ8zMAlAXGoSeGVl/vNrH00Ez/4ZZzsQvHd9Z7sWfktF4Cv3\nHv/9aM756R/7lW78/xFKjsV2AOJMAss2/ynIGkdcIR1eYhKAOJPAmxxx1f/IFMCymAQgLzUJ/L06\nv2sVNAFwNqkI/G3tzXrvba9bN5O3yTgb2wGIy04CaxVX9K+u+dE2ovh3dQUmAYgTgReMMb69ah7Z\nx+9T2PL7FTge24GgtZ+VWHvj2wacm0kA4kRgA+WVsHztVyECECcCYa+s4vcORTkXEXijM5yqu5kR\nAYjzFuFGbr3tdsUV9orXVGcSgDiTwMbOtlI+c2ZxtmtjHZMAxJkEeMgEcG0iEOajwSyL7QDkiQDE\niQDEORPgE2cBLSYB/iEAPSIAcSIAcSIAcQ4Gw+z/WRaTAOSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJ\nAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJ\nAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSJAMSNOeferwHYkUkA4kQA4kQA4kQA4kQA4kQA\n4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4kQA4n4B3k+x\nM4kwiDoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAElCAYAAABgRJorAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAK+D8iPZhV/wFmCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAE/CAYAAADSet/SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots for the write up\n",
    "digits = resize_digits(digits, 28)\n",
    "_, (ax2, ax3, ax4) = plt.subplots(1, 3, sharex='col', sharey='row', figsize=(15, 5))\n",
    "ax2.imshow(digits[0], cmap = 'gray')\n",
    "ax2.axis('off')\n",
    "ax3.imshow(digits[1], cmap = 'gray')\n",
    "ax3.set_title('Separated Digits')\n",
    "ax3.axis('off')\n",
    "ax4.imshow(digits[2], cmap = 'gray')\n",
    "ax4.axis('off')\n",
    "plt.show()\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize = (5,5))\n",
    "ax.imshow(test_images[0], cmap = 'gray')\n",
    "ax.axis('off')\n",
    "ax.set_title('Test Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split up the digits in the testset\n",
    "import skimage \n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import dilation\n",
    "from skimage.transform import resize\n",
    "\n",
    "digit_1 = []\n",
    "digit_2 = []\n",
    "digit_3 = []\n",
    "for i in range(0, len(test_images)):\n",
    "    digits = get_digits(test_images, i)\n",
    "    if len(digits) != 3: \n",
    "        print('ERROR NOT THREE DIGITS')\n",
    "        print(i)\n",
    "        break\n",
    "    resized = resize_digits(digits, 28)\n",
    "    digit_1 += [resized[0]]\n",
    "    digit_2 += [resized[1]]\n",
    "    digit_3 += [resized[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid_1 = torch.from_numpy(np.array(digit_1).reshape(10000,1,28,28))\n",
    "X_valid_2 = torch.from_numpy(np.array(digit_2).reshape(10000,1,28,28))\n",
    "X_valid_3 = torch.from_numpy(np.array(digit_3).reshape(10000,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validloader_1 = torch.utils.data.DataLoader(X_valid_1, batch_size=64)\n",
    "validloader_2 = torch.utils.data.DataLoader(X_valid_2, batch_size=64)\n",
    "validloader_3 = torch.utils.data.DataLoader(X_valid_3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "#Make the final predictions\n",
    "pred_1 = []\n",
    "pred_2 = []\n",
    "pred_3 = []\n",
    "\n",
    "for batch_idx, inputs in enumerate(validloader_1):\n",
    "    inputs = Variable(inputs)\n",
    "    outputs = clf(inputs.float())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    pred_1.extend(predicted.tolist())\n",
    "\n",
    "for batch_idx, inputs in enumerate(validloader_2):\n",
    "    inputs = Variable(inputs)\n",
    "    outputs = clf(inputs.float())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    pred_2.extend(predicted.tolist())\n",
    "\n",
    "for batch_idx, inputs in enumerate(validloader_3):\n",
    "    inputs = Variable(inputs)\n",
    "    outputs = clf(inputs.float())\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    pred_3.extend(predicted.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the maximum prediction\n",
    "pred = []\n",
    "for i in range(len(pred_1)):\n",
    "    predict = max(pred_1[i], pred_2[i], pred_3[i])\n",
    "    pred += [predict]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = pd.DataFrame()\n",
    "final_preds['Id'] = list(range(0,10000))\n",
    "final_preds['Label'] = pred\n",
    "final_preds.to_csv('Prediction_6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
